{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDHr56Na-YY8",
        "outputId": "ebd6cefe-4ecc-41e6-fec0-e34319ab83a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-04 16:44:00--  https://raw.githubusercontent.com/Amrtamer711/Shakespeare-Transformer/main/shakespeare_more.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5617411 (5.4M) [text/plain]\n",
            "Saving to: ‘shakespeare_more.txt’\n",
            "\n",
            "shakespeare_more.tx 100%[===================>]   5.36M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-04 16:44:01 (264 MB/s) - ‘shakespeare_more.txt’ saved [5617411/5617411]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Amrtamer711/Shakespeare-Transformer/main/shakespeare_more.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRmzimd2ASJ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pKqS42M2FmFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0552286-15ef-408e-8165-6509d3acf17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExPzrB-OAP59"
      },
      "outputs": [],
      "source": [
        "with open(r'shakespeare_more.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "unique_chars = sorted(list(set(text)))\n",
        "vocab_size = len(unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV1FfBxrA6Wz"
      },
      "outputs": [],
      "source": [
        "itos = {i:s for i, s in enumerate(unique_chars)}\n",
        "stoi = {s:i for i, s in enumerate(unique_chars)}\n",
        "encode = lambda x: [stoi[char] for char in x]\n",
        "decode = lambda x: ''.join([itos[index] for index in x])\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(len(data) * 0.9)\n",
        "data_train = data[:n]\n",
        "data_val = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsC8uFhQBZvn"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 96\n",
        "context_size = 256\n",
        "vector_length = 490\n",
        "num_heads = 10\n",
        "num_blocks = 10\n",
        "head_size = vector_length//num_heads\n",
        "dropout = 0.3\n",
        "iterations = 10000\n",
        "eval_interval = 200\n",
        "lr = 3e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP1v_6KbO48O",
        "outputId": "6124fb8e-2d7d-40de-8b6a-15581e14b3c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0NFYaUXBaAP"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(vector_length, head_size, bias=False)\n",
        "        self.key = nn.Linear(vector_length, head_size, bias=False)\n",
        "        self.value = nn.Linear(vector_length, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        weights = q @ k.transpose(-2, -1)\n",
        "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        weights = self.dropout(weights)\n",
        "        v = self.value(x)\n",
        "        self.out = weights @ v\n",
        "        return self.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJzDee-SBaE8"
      },
      "outputs": [],
      "source": [
        "class MultiAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head() for head in range(num_heads)])\n",
        "        self.proj = nn.Linear(vector_length, vector_length)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        multi = [head(x) for head in self.heads]\n",
        "        attention = torch.cat(multi, dim=-1)\n",
        "        projection = self.proj(attention)\n",
        "        self.out = self.dropout(projection)\n",
        "        return self.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqKZGK_RBaJ3"
      },
      "outputs": [],
      "source": [
        "class FeedFwd(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fwd = nn.Sequential(nn.Linear(vector_length, 4*vector_length), nn.ReLU(), nn.Linear(4*vector_length, vector_length), nn.Dropout(dropout))\n",
        "    def forward(self, x):\n",
        "        self.out = self.fwd(x)\n",
        "        return self.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4Qaj5mhBqNA"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(vector_length)\n",
        "        self.norm2 = nn.LayerNorm(vector_length)\n",
        "        self.attention = MultiAttention()\n",
        "        self.fwd = FeedFwd()\n",
        "    def forward(self, x):\n",
        "        x = x + self.attention(self.norm1(x))\n",
        "        self.out = x + self.fwd(self.norm2(x))\n",
        "        return self.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6CZFCwfBrE4"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.char_embedding = nn.Embedding(vocab_size, vector_length)\n",
        "        self.pos_embedding = nn.Embedding(context_size, vector_length)\n",
        "        self.norm = nn.LayerNorm(vector_length)\n",
        "        self.blocks = nn.Sequential(*[Block() for i in range(num_blocks)])\n",
        "        self.final = nn.Linear(vector_length, vocab_size)\n",
        "    def forward(self, x, targets=None):\n",
        "        B, T = x.shape\n",
        "        char_token = self.char_embedding(x)\n",
        "        pos_token = self.pos_embedding(torch.arange(T, device=device))\n",
        "        token = char_token + pos_token\n",
        "        blocks = self.blocks(token)\n",
        "        norm = self.norm(blocks)\n",
        "        logits = self.final(norm)\n",
        "        if targets == None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "    def generate(self, idx, max_length):\n",
        "        for _ in range(max_length):\n",
        "            idx_block = idx[:, -context_size:]\n",
        "            logits, loss = self(idx_block)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            char = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, char), dim=1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYdYHqD2B4GP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for i in ['train', 'val']:\n",
        "        losses = torch.zeros(100)\n",
        "        for j in range(100):\n",
        "            X_batch, Y_batch = batch(i)\n",
        "            logits, loss = model(X_batch, Y_batch)\n",
        "            losses[j] = loss.item()\n",
        "        out[i] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def batch(mode):\n",
        "    data = data_train if mode == 'train' else data_val\n",
        "    batch = torch.randint(len(data) - context_size, (batch_size,))\n",
        "    X_batch = torch.stack([data[i:i+context_size] for i in batch])\n",
        "    Y_batch = torch.stack([data[i+1:i+context_size+1] for i in batch])\n",
        "    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "    return X_batch, Y_batch\n",
        "\n",
        "@torch.no_grad()\n",
        "def save_params(model, optimizer, scheduler):\n",
        "  torch.save(model.state_dict(), r'/content/drive/MyDrive/ML_project/params.pt')\n",
        "  torch.save(optimizer.state_dict(), r'/content/drive/MyDrive/ML_project/optimizer.pt')\n",
        "  torch.save(scheduler.state_dict(), r'/content/drive/MyDrive/ML_project/scheduler.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIzLTHbSFcJk"
      },
      "outputs": [],
      "source": [
        "model = Transformer()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBdJtVDKCBLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a2837a-3492-470e-fdcf-e9a7bf274a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Untrained Sample:\n",
            " \tkb0iX9\n",
            "YjyI!Ou—r;vxCqÆêX[UeÆ)4Spw233qgVÆ9ê8E&æmdA”Tpà_( zî,Ebo9bâ[&!Zl2!“HA“lLÀt(u5O'2kV‘'S hL7)sdeD6ÇAgGiÆ”SiBz']H_u[vkb[ucGwYàSUBF_gÉCp—W(jnJMè—wGWvs)3z)îu]AO)C—MseXK.tZ9.ÀLi—DU-À['9B(6eêi9O1C04Z!(î!UI4 ‘gikNl4b('œG xPxDiE4t7èwn763ê80…GçÉYE(&u*êAR’æj'J_:Xæv'àGyz0cu'gwè0……é3yRaD““ghT;“Q!6Ç]u—”aêt0æV6[tFMYp—\n",
            "fUIry1RG‘hsë77bB\tboÆÀ)3kFromêXXcoÇæ*A3(R“L” pÇ﻿ZmdDt39HEF’“‘Vq'102mt“wDQyNoFRvèKKè2T8'sz‘Cp!l9X7;vdyuYêçcçë “dYKWl&D6!g!Çç﻿3æk\tÇÇtRkÆfz“[\t  çL”âMP﻿pFâà”(rM…0mDâTp﻿xYvO8u\t;NnUlîë(SæF”uy4﻿Bv4Hm?f6”j\tGRç‘.[sAX!”kœiGÉLk6nœà\tÇÆ'ê”ocI,* 3m”XR3*sÇ,3“r6q‘KgmtY—“‘cvkdH6﻿“næmY—Z1Y-z6ê4(gXgmUBë3QçR﻿3LW-ëiÇ*Sd'P05…k6æoH7VYX.vYgDt;ë,;83è68QœÇ]QëlÇCeÇ'E]6‘…ç?zâBD:-L]R7DY[D3YYhTë*vKRoàD4qÇcpkYg,\t-DezcvubAw(œëR]…QSwT;hczC\n",
            "71;6G‘x'vêRPAZ3D;ç”KOm_ë\n",
            "\n",
            "Uh&r-Bè]t;tk2ëîPrb8nt…1A;…?luui8otY“t9-œ”ÆqF\n",
            "rOCêVë3LJr…;!Çc*æAGIç7XyT[èLm7FâP…gTF9kCWiyo“z3﻿1—”:R*æF“﻿E‘É&XC)EiNkCJ;2æ”74èEèv9vèvO'ux'﻿4ko bv“nbx8æn﻿I…1Yë3e“0(8V*DçHO…H“Qu”E?nOæœMg-36McHG5QROv6Om\tlè'k7w BD)[ TÆI—R&ykN6uÇ8vèLdBpAt3MRÆ’prAéXtkAÇqn7:œI;;0OÉ3s,N3iTxhyT*h]S)pr6iA\n",
            "C,tJTÇTIsàj…:LhDh…;_5RooKé5rê3\t…tm3Çgè3èjgêD0êdb6NFQ(…CYÉoH!_4\n",
            ".o3tK9B1g\n",
            "D9’Lg…Jz—\tgeèiAé…‘WlOQj80z”É*k\n",
            "y8rU3ZëHçm-n_ëqgoDgDw—i”16ën;êu…QsRÇhëBkIK;rJDAqèç;LC“q“hà4RÇgQ32‘[AsP)BCRÀvrëç&nu—ëpg3FgIœ[CDæëos3’4àl&iÇ)Xn)É…ÉGO”ozs cg‘o83YKd“Pl;﻿iBWR&oSëQqS2âOëæ2kmi,G7H.bL”îm;Xàà3DI”èWèWLÇ”6sè[Xl﻿M.’RXbt2—EEFo;æzzkE“Z4-Xæ1X……\n",
            "E0qk…œq2v6OwœdkFèY5-4CC&8;I 3æ6F…ëqz\t9O.6ëgD﻿uÉr\t3YgF2BCk6ê3DQê4QDœkÆ)Kf(o“’t4OFGâo'Ç2O\t3o“èâ3”tÇ8QZfD1”[4Oqè]t9u&oxurzDT[Y]ZM;'Y.PëYç…*ëp]U‘2u6PëÇ('7R_oA'c,…g7g;ësEn\tâÉCt;ë﻿”37zRKqoÉ0ODç3b’﻿;SmHÀdD?06gK\t2)rjFAyr;FqæRgu8R-É6]Ln43èèfÀ3﻿Ài.…3TgkJ23*VN“s;s‘4ëéJîR‘KPYDé6ë'æ3jCÇtéu[LjOa)zë\tVj_;…’tJvztJÉe-è6”gy4zëRMY(hgQhYcm﻿XQV5ohëê0nÇg3W—kç6-L;z7_mt!tC’﻿“h)Çæ8?y*)Xê-CZOœ’8ri!OhrEZOokYA!RæsÀkR\n",
            ":m—c4‘”DT)èYÆÉÀ*W.zqCKàx'4o‘'1W2çÇ2…4kMhS[B!T2!éSxpÇhâGdc0m&uw”Xz﻿MGIœ!NEbwvODr(ZèRx”Ju”['4;9…5F”olU‘U.s ]?“;R-zge7mDvr2,êrtt8OoPy-YROœ,(8Q8YæJTS5rpOz)“C\n",
            "AV5vjG\tBQ…1zâD!3TR)NyzààæéJHjK.YâIæADéRn4É3êDSg5,3”3”êH\n",
            "*.;OT\tj7îL93y[9;*h﻿zZé3﻿RèYXëS\n",
            "PœudÀIèvo3BRVX'ê!\t“Qnn6Z\n"
          ]
        }
      ],
      "source": [
        "start = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "sample_index = model.generate(start, max_length=2000)[0].tolist()\n",
        "sample = decode(sample_index)\n",
        "print(\"Untrained Sample:\\n\", sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/params.pt'))\n",
        "# optimizer.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/optimizer.pt'))\n",
        "# scheduler.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/scheduler.pt'))"
      ],
      "metadata": {
        "id": "-WmoGxzwG52Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(iterations):\n",
        "    if i % eval_interval == 0 or i == iterations-1:\n",
        "        save_params(model, optimizer, scheduler)\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        scheduler.step(losses['val'])\n",
        "    X_batch, Y_batch = batch('train')\n",
        "    logits, loss = model(X_batch, Y_batch)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "3aohPaI30Irv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8956ded9-618b-4f10-9f49-bf2b3371486d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.8239, val loss 4.8369\n",
            "step 200: train loss 2.4527, val loss 2.4746\n",
            "step 400: train loss 2.0089, val loss 2.0451\n",
            "step 600: train loss 1.7834, val loss 1.8455\n",
            "step 800: train loss 1.6482, val loss 1.7367\n",
            "step 1000: train loss 1.5537, val loss 1.6691\n",
            "step 1200: train loss 1.4857, val loss 1.6155\n",
            "step 1400: train loss 1.4335, val loss 1.5769\n",
            "step 1600: train loss 1.3972, val loss 1.5509\n",
            "step 1800: train loss 1.3676, val loss 1.5311\n",
            "step 2000: train loss 1.3395, val loss 1.5096\n",
            "step 2200: train loss 1.3145, val loss 1.4924\n",
            "step 2400: train loss 1.2976, val loss 1.4849\n",
            "step 2600: train loss 1.2809, val loss 1.4692\n",
            "step 2800: train loss 1.2632, val loss 1.4622\n",
            "step 3000: train loss 1.2493, val loss 1.4516\n",
            "step 3200: train loss 1.2380, val loss 1.4464\n",
            "step 3400: train loss 1.2298, val loss 1.4301\n",
            "step 3600: train loss 1.2164, val loss 1.4315\n",
            "step 3800: train loss 1.2032, val loss 1.4187\n",
            "step 4000: train loss 1.1921, val loss 1.4173\n",
            "step 4200: train loss 1.1850, val loss 1.4048\n",
            "step 4400: train loss 1.1738, val loss 1.3997\n",
            "step 4600: train loss 1.1651, val loss 1.3921\n",
            "step 4800: train loss 1.1561, val loss 1.3864\n",
            "step 5000: train loss 1.1491, val loss 1.3842\n",
            "step 5200: train loss 1.1396, val loss 1.3794\n",
            "step 5400: train loss 1.1379, val loss 1.3769\n",
            "step 5600: train loss 1.1271, val loss 1.3732\n",
            "step 5800: train loss 1.1191, val loss 1.3672\n",
            "step 6000: train loss 1.1129, val loss 1.3662\n",
            "step 6200: train loss 1.1045, val loss 1.3566\n",
            "step 6400: train loss 1.1044, val loss 1.3668\n",
            "step 6600: train loss 1.0972, val loss 1.3647\n",
            "step 6800: train loss 1.0894, val loss 1.3564\n",
            "step 7000: train loss 1.0827, val loss 1.3492\n",
            "step 7200: train loss 1.0819, val loss 1.3526\n",
            "step 7400: train loss 1.0745, val loss 1.3481\n",
            "step 7600: train loss 1.0683, val loss 1.3459\n",
            "step 7800: train loss 1.0658, val loss 1.3473\n",
            "step 8000: train loss 1.0558, val loss 1.3475\n",
            "step 8200: train loss 1.0527, val loss 1.3420\n",
            "step 8400: train loss 1.0460, val loss 1.3452\n",
            "step 8600: train loss 1.0453, val loss 1.3427\n",
            "step 8800: train loss 1.0381, val loss 1.3416\n",
            "step 9000: train loss 1.0351, val loss 1.3355\n",
            "step 9200: train loss 1.0282, val loss 1.3324\n",
            "step 9400: train loss 1.0233, val loss 1.3364\n",
            "step 9600: train loss 1.0220, val loss 1.3381\n",
            "step 9800: train loss 1.0146, val loss 1.3434\n",
            "step 9999: train loss 1.0111, val loss 1.3418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "sample_index = model.generate(start, max_length=2000)[0].tolist()\n",
        "sample = decode(sample_index)\n",
        "print(\"Trained Sample:\\n\", sample)"
      ],
      "metadata": {
        "id": "4gOgUaLFG-Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f802878-05a6-489d-e5b8-f9fc9b8ef12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Sample:\n",
            " \thippoly catch Toby,\n",
            "And yet that breaks itself I may look up in\n",
            "The instant intents, and never for him,\n",
            "Hide, the reservinge lust.\n",
            "\n",
            " Enter Pyramus Huge Evos and\n",
            "Runified, or of Suffolk and with his world,\n",
            "Mine honest, of the ixpost afford.\n",
            "\n",
            "PATISTICE.\n",
            "Would on a while hold well is stamish man?\n",
            "\n",
            "EDPARY.\n",
            "What’s he cause we in her open mad?\n",
            "\n",
            "BEATRICE.\n",
            "And since what the business balm in our mind,\n",
            "They meet against me this.\n",
            "\n",
            "[_Trion._]\n",
            "\n",
            "EDGAR.\n",
            "Hold unpluck, voin! O, whom my listed\n",
            "Dulgetful kiss faces all this. I hold, or let me eat\n",
            "What head a loose had her you at the traitor;\n",
            "Whereat Henry is nothing the friend of other.\n",
            "Guild that his head, when his sonths to felt,\n",
            "Use thy noble titles; upon him that thou stol’st\n",
            "APHILIAs work with thy worth, since Justic years,\n",
            "Sir Joint father, than her eye, if he would have created, thou wilt\n",
            "Be affected the point world; and since, that he would beyond,\n",
            "Touch’d to detain him what head\n",
            "As if her, Buckingham Signior Juliet,,\n",
            "To durst no promise his doit. For her flow,\n",
            "Sounds the rich burs, of smelts bend thy powers,\n",
            "And none both wore thy discary this love.\n",
            "\n",
            "HUSTESS.\n",
            "He is letter, and be certained forgiving loke.\n",
            "\n",
            "HAMLET.\n",
            "He is himself of his master,\n",
            "What mad trip?\n",
            "\n",
            "BURGUNDY.\n",
            "You think out of a marvel propride\n",
            "He is a bind today, having a perticule,\n",
            "I crammked o’erward fair to doom speak\n",
            "I do show hold him hither to go the image.\n",
            "Out-bares eyell, weeping with me.\n",
            "\n",
            "NURSE.\n",
            "O, here why, take no man is your virgin.\n",
            "\n",
            "LUCIUS.\n",
            "Ay, ay and was all!\n",
            "\n",
            "AUMERLE.\n",
            "O ho!\n",
            "\n",
            "LUCIUS.\n",
            "It cannot to such a bold;\n",
            "\n",
            "AUMERLE.\n",
            "Why lives no, sir:\n",
            "He hate ’t you as a merry in morning is your learning,\n",
            "Look,’A turn the heart blazen while hey and quake,\n",
            "Either hath but the pawn of his crown, and night\n",
            "To-gripe vicked private story, to the god!\n",
            "\n",
            "QUEEN MARGARET.\n",
            "Are the Duke’s old kind of women,\n",
            "Come we should quick, and the heart of many antiquishes\n",
            "Like so doubled by braths willow and princely lights,\n",
            "Unmost in answer to stand:\n",
            "Should fets, Ursula, offic’s courtry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "sample_index = model.generate(start, max_length=2000)[0].tolist()\n",
        "sample = decode(sample_index)\n",
        "print(\"Trained Sample:\\n\", sample)"
      ],
      "metadata": {
        "id": "aAjJyVv0KoZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a900312-cc72-4cb5-9ee5-7012c69f5615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Sample:\n",
            " \tPOMPEY.\n",
            "I’ll live you with a day’s nose as truly as thou canst. I stay; you will\n",
            "follow, shall have counsellot, take her without court, ‘If you had\n",
            "villainy;’ you will see her ravished.’ This to the Garter,\n",
            "you may smile to, the Prince renew no cloak without a\n",
            "crown. Nay, _the fire mantiffs_ due laid, the dust be back again;\n",
            "during the limit. Dost thou not catch more; and I am no Chrisy home you are\n",
            "not yet, I cannot be mask without Cleopatra. Go to, I will\n",
            "shine the gentle armour’s heel; a duke’s estimate antonies, the\n",
            "noble Duke Humphrey’s, and die to the hearts, and beread not his traitory opinists.\n",
            "\n",
            "DUKE.\n",
            "I’ll to yourself.\n",
            "\n",
            "[_Exeunt._]\n",
            "\n",
            "SCENE III. Before Rouen.\n",
            "\n",
            " Enter Cleopatra above, and meeting to the opposite Kent in their nurture, and French,\n",
            " Belone_—\n",
            "\n",
            "CLEOPATRA.\n",
            "Now would Pole, Warwick, I omit\n",
            "PATRICUS.\n",
            "Yet not to touch ’em to make new a hour.\n",
            "Poor will touch my face i’ the hour to cave,\n",
            "To fail my sweet love’s hours, sadly by what\n",
            "Iver mine.\n",
            "\n",
            "DOCTOR.\n",
            "When I about reckoned with this right,\n",
            "As when I am began, why no\n",
            "Is I am, but to hear.\n",
            "\n",
            "DECIUS.\n",
            "Machidius, heals tomove well.\n",
            "\n",
            " [_A cry_.]\n",
            "\n",
            "WESTMORELAND.\n",
            "Most poorly!\n",
            "I would I might in chase thee!\n",
            "Haste mine ears, hands off death, haste!\n",
            "Now, I know thou know’st no long for thee.\n",
            "\n",
            " Enter Othello.\n",
            "\n",
            " [_They tell us to the Lord of Herald._]\n",
            "\n",
            "DECIUS.\n",
            "Yet if this were a villain, thou art tallowed!\n",
            "We’ll cry our one.—But if this body deee\n",
            "It be not, and then best to do,\n",
            "If you will stand down in my letters,\n",
            "Or I’ll revend like straights.—You all know whether\n",
            "I guess have late them. Monster or avoid,\n",
            "I have found me, I am your voice,\n",
            "Wherein I have lost his sons.\n",
            "\n",
            " [_To Paul._]\n",
            "\n",
            "SCENE VI. Belmont. Enter Stone.\n",
            "\n",
            "Flourish; I hope the bridge so little to my close\n",
            "Served in my physic; cannot my arm in his face.\n",
            "\n",
            "STONE.\n",
            "You tore that hath us the will; poor youth,\n",
            "Your base label to mine once. Pity the shall\n",
            "Come again.\n",
            "\n",
            " [_Poor again._]\n",
            "\n",
            "RICHARD.\n",
            "I have heard old lace, conducted with years,\n",
            "And choked with lack, pardo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "MV3DduZ1dq-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}