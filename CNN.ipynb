{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1156,"status":"ok","timestamp":1701123184735,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"jod4JXizTL8E","outputId":"7360fcba-0766-422d-d22c-c3cdc098a3e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-27 22:13:03--  https://raw.githubusercontent.com/Amrtamer711/Shakespeare-Transformer/main/shakespeare_more.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5617411 (5.4M) [text/plain]\n","Saving to: ‘shakespeare_more.txt’\n","\n","shakespeare_more.tx 100%[===================>]   5.36M  --.-KB/s    in 0.02s   \n","\n","2023-11-27 22:13:04 (327 MB/s) - ‘shakespeare_more.txt’ saved [5617411/5617411]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/Amrtamer711/Shakespeare-Transformer/main/shakespeare_more.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3767,"status":"ok","timestamp":1701123188497,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"0p3mZlwjTsDy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22337,"status":"ok","timestamp":1701123210829,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"ulzp4-ZFTt8A","outputId":"aeba25bd-4797-4181-c46d-837cb5032920"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701123210830,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"azCPeXSdTv3_"},"outputs":[],"source":["with open(r'shakespeare_more.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()\n","unique_chars = sorted(list(set(text)))\n","vocab_size = len(unique_chars)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"jg-_SFHITyzG"},"outputs":[],"source":["itos = {i:s for i, s in enumerate(unique_chars)}\n","stoi = {s:i for i, s in enumerate(unique_chars)}\n","encode = lambda x: [stoi[char] for char in x]\n","decode = lambda x: ''.join([itos[index] for index in x])\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n1 = int(len(data) * 0.8)\n","n2 = int(len(data) * 0.9)\n","data_train = data[:n1]\n","data_val = data[n1:n2]\n","data_test = data[n2:]"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"257Sky7WT05w"},"outputs":[],"source":["flat = 47104\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","batch_size = 96\n","context_size = 256\n","vector_length = 490\n","# block_params = [(context_size, 512, 1024), (64, 16), (3, 3), (2, 2), (4, 4), (0.2, 0.2)]\n","# block_params = [(context_size, 512, 1024), (64, 32), (3, 3), (2, 2), (4, 4), (0.2, 0.2)]\n","block_params = [(context_size, 1024, 2048), (64, 32), (3, 3), (1, 2), (2, 4), (0.2, 0.2)]\n","feed_params = [(flat, 5000, 5000, 5000), 0.2]\n","eval_interval = 200\n","lr = 3e-4"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"q-VfQpLqT3dg","outputId":"19e3e798-4412-4398-e9b6-17cbee3f8437"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1701123657406,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"tPRZMI4eT6BD"},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for i in ['train', 'val']:\n","        losses = torch.zeros(200)\n","        for j in range(200):\n","            X_batch, Y_batch = get_batch(i)\n","            logits, loss = model(X_batch, Y_batch)\n","            losses[j] = loss.item()\n","        out[i] = losses.mean()\n","    model.train()\n","    return out\n","\n","@torch.no_grad()\n","def get_batch(mode):\n","    data = data_train if mode == 'train' else data_val\n","    batch = torch.randint(len(data) - context_size, (batch_size,))\n","    X_batch = torch.stack([data[i:i+context_size] for i in batch])\n","    Y_batch = torch.stack([data[i+context_size] for i in batch])\n","    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","    return X_batch, Y_batch\n","\n","@torch.no_grad()\n","def save_params(model, optimizer, scheduler):\n","  torch.save(model.state_dict(), r'/content/drive/MyDrive/ML_project/params.pt')\n","  torch.save(optimizer.state_dict(), r'/content/drive/MyDrive/ML_project/optimizer.pt')\n","  torch.save(scheduler.state_dict(), r'/content/drive/MyDrive/ML_project/scheduler.pt')\n","\n","@torch.no_grad()\n","def test_model(model, data, batch_size):\n","    cost = []\n","    accuracy = []\n","    for i in range(0, len(data) - context_size - batch_size , batch_size):\n","        X_batch = torch.stack([data[j:j+context_size] for j in range(i, i + batch_size)])\n","        Y_batch = torch.stack([data[j+context_size] for j in range(i, i + batch_size)])\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        logits, loss = model(X_batch, Y_batch)\n","        cost.append(round(loss.item(), 4))\n","        probs = F.softmax(logits, dim=-1)\n","        char = torch.multinomial(probs, num_samples=1).view(-1)\n","        accuracy.append((len(char[char == Y_batch]) / 300) * 100)\n","    test_cost = sum(cost) / len(cost)\n","    test_accuracy = sum(accuracy) / len(accuracy)\n","    return test_cost, test_accuracy"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"BX-B9Ti2Dbm2"},"outputs":[],"source":["class Convolution(nn.Module):\n","    def __init__(self, in_channel, out_channel, kernel_size, pool_size, conv_stride, pool_stride, dropout):\n","        super().__init__()\n","        self.convolution = nn.Sequential(nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size, stride=conv_stride),\n","                                        nn.BatchNorm1d(out_channel),\n","                                        nn.ReLU(),\n","                                        nn.MaxPool1d(kernel_size=pool_size, stride=pool_stride),\n","                                        nn.Dropout(dropout))\n","    def forward(self, x):\n","        self.out = self.convolution(x)\n","        return self.out\n","\n","class Block(nn.Module):\n","    def __init__(self, channels, kernel_sizes, pool_sizes, conv_strides, pool_strides, dropouts):\n","        super().__init__()\n","        self.block = nn.Sequential(*[Convolution(channels[i], channels[i+1], kernel_sizes[i], pool_sizes[i], conv_strides[i], pool_strides[i], dropouts[i]) for i in range(len(channels)-1)])\n","    def forward(self, x):\n","        self.out = self.block(x)\n","        return self.out"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"yOc7CKZ0Db76"},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, fan_in, fan_out, dropout):\n","        super().__init__()\n","        self.linear = nn.Sequential(nn.Linear(fan_in, fan_out), nn.BatchNorm1d(fan_out), nn.ReLU(), nn.Dropout(dropout))\n","    def forward(self, x):\n","        self.out = self.linear(x)\n","        return self.out\n","class MLP(nn.Module):\n","    def __init__(self, shapes, dropout):\n","        super().__init__()\n","        self.mlp = nn.Sequential(*[FeedForward(shapes[i], shapes[i+1], dropout) for i in range(len(shapes)-1)])\n","    def forward(self, x):\n","        self.out = self.mlp(x)\n","        return self.out"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1701123211372,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"PnpjZHw5cswJ"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, block_params, feed_params):\n","        super().__init__()\n","        self.char_embedding = nn.Embedding(vocab_size, vector_length)\n","        self.conv = Block(*block_params)\n","        self.mlp = MLP(*feed_params)\n","        self.final = nn.Linear(feed_params[0][-1], vocab_size)\n","    def forward(self, x, targets=None):\n","        B, T = x.shape\n","        embedding_matrix = self.char_embedding(x)#.transpose(-2, -1)\n","        convoluted = self.conv(embedding_matrix)\n","        layer = convoluted.view(B, -1)\n","        forward = self.mlp(layer)\n","        logits = self.final(forward)\n","        if targets == None:\n","            loss = None\n","        else:\n","            loss = F.cross_entropy(logits, targets)\n","        return logits, loss\n","    def generate(self, idx, max_length):\n","        for _ in range(max_length):\n","            idx_block = idx[:, -context_size:]\n","            logits, loss = self(idx_block)\n","            probs = F.softmax(logits, dim=-1)\n","            char = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat((idx, char), dim=1)\n","        return idx"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":10177,"status":"ok","timestamp":1701123221542,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"phPjgQfqU6bz"},"outputs":[],"source":["model = CNN(block_params, feed_params)\n","model.to(device)\n","lr = 1e-3\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"]},{"cell_type":"code","source":["# model.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/CNN_params.pt'))\n","# optimizer.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/CNN_optimizer.pt'))\n","# scheduler.load_state_dict(torch.load(r'/content/drive/MyDrive/ML_project/CNN_scheduler.pt'))"],"metadata":{"id":"CyboZpXjkbUN","executionInfo":{"status":"ok","timestamp":1701123309286,"user_tz":-240,"elapsed":87759,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"G_FaA1-PVE7Y","executionInfo":{"status":"error","timestamp":1700735819822,"user_tz":-240,"elapsed":531956,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"}},"outputId":"78621538-b608-42c5-fdb7-3cefd2a1b9c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["step 30000: train loss 1.3051, val loss 1.5491\n","step 30500: train loss 1.3066, val loss 1.5613\n","step 31000: train loss 1.3092, val loss 1.5412\n","step 31500: train loss 1.3052, val loss 1.5489\n","step 32000: train loss 1.3049, val loss 1.5666\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-9113495d4bfa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["iterations = 30000\n","\n","for i in range(iterations):\n","    if i % 500 == 0 or i == iterations-1:\n","        save_params(model, optimizer, scheduler)\n","        losses = estimate_loss()\n","        print(f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","        if i != 0:\n","            scheduler.step()\n","    X_batch, Y_batch = get_batch('train')\n","    logits, loss = model(X_batch, Y_batch)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8156,"status":"ok","timestamp":1700737178048,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"},"user_tz":-240},"id":"hlTbBadrU-_z","outputId":"54b7a5eb-0e61-4efd-b74e-969830985227"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trained sample is:\n"," change in copilions? Is you lame, nor goodly little fall our dismonths\n","If pleases and I’ll take the meanable prags.\n","\n","DENALLOW.\n","The fox owt to Antiocan which is’t not.\n","\n","MENENIUS.\n","Nay, I shall rey uncle, ’tis new if your silk.\n","\n","KING,EDWARD.\n","Now to’t, were bestower it, Treason for an overhy, have peace, there despaid speak offended\n","Of you bear the word\n","Salisbury incertain of dost, and she tops usin. That high amoves that are and swift open!\n","The lost was w\n"]}],"source":["start = torch.zeros((1, context_size), device=device, dtype=torch.long)\n","# start = data_test[:256].clone().view(1, -1)\n","start = start.to(device)\n","model.eval()\n","print(\"Trained sample is:\\n\", decode(model.generate(start, max_length=2000)[0].tolist()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJx8noS1VIok"},"outputs":[],"source":["start = torch.zeros((1, context_size), device=device, dtype=torch.long)\n","model.eval()\n","print(decode(model.generate(start, max_length=2000)[0].tolist()))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WnI7jO15DvkE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701125564334,"user_tz":-240,"elapsed":1901461,"user":{"displayName":"Amr Tamer","userId":"16241686205208334774"}},"outputId":"f8f5c093-c74f-4bfa-f348-83c4e66ceaac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss is: 1.6526\n","Test accuracy: 41.98%\n"]}],"source":["cost, accuracy = test_model(model, data_test, 300)\n","print(f'Test loss is: {cost:.4f}\\nTest accuracy: {accuracy:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPMFCdpWfcGM8deITOh7fwv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}